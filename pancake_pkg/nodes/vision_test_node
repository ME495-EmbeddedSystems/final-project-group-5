#!/usr/bin/env python

from numpy.core.defchararray import lower
import rospy
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image, CompressedImage, CameraInfo
import numpy as np
import cv2
import pyrealsense2 as rs
import tf2_ros
import tf2_geometry_msgs
from geometry_msgs.msg import TransformStamped
from tf import transformations, TransformListener


class ImageProcessing:

    def __init__(self):
        rospy.init_node('vision_test_node',anonymous=True, log_level=rospy.DEBUG)
        rospy.logerr("started the node")
        rospy.sleep(2)
        rospy.Subscriber("/camera/aligned_depth_to_color/image_raw", Image, callback=self.convert_depth_image, queue_size=1)
        rospy.Subscriber("/camera/color/image_raw", Image, callback=self.convert_color_image, queue_size=1)
        rospy.Subscriber("/camera/aligned_depth_to_color/camera_info", CameraInfo, callback=self.get_intrinsics, queue_size=1)
        rospy.set_param("/pancaked", False)
        rospy.set_param("/flipped", False)
        rospy.set_param("/flip_time", False)
        # rospy.set_param("/saved_pancake_pose", True)

        self.point_counter = 0
        self.point_matrix = np.zeros((4,2),np.int)
        self.first_frame_after_pour = True
        self.flag2 = False
        
        rospy.logerr('subscribed')

    def show_video(self, name, ros_image):
        """ TODO

        TODO

        Args:
            name (TODO) : TODO
            ros_image (TODO) : TODO
        Returns:
            None
        """
        cv2.imshow(name,ros_image)
        cv2.waitKey(3)

        return

    def convert_depth_image(self,ros_image):
        """ TODO
        
        TODO

        Args:
            ros_image (TODO) : TODO
        Returns:
            None
        """
        bridge = CvBridge()
        # Use cv_bridge() to convert the ROS image to OpenCV format
        try:
            self.depth_image = bridge.imgmsg_to_cv2(ros_image)
            depth_array = np.array(self.depth_image, dtype=np.float32)
            #self.show_video(depth_image)

        except CvBridgeError:
            print(CvBridgeError())
            rospy.logerr("bad")
        
        return

    def convert_color_image(self,ros_image):
        """ TODO

        TODO

        Args:
            ros_image (TODO) : TODO
        Returns:
            None
        """

        bridge = CvBridge()
        try:
            self.bgr_image = bridge.imgmsg_to_cv2(ros_image)
            self.hsv_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2HSV)
            self.rgb_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2RGB)
            self.grayscale_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2GRAY)

            # while self.point_counter < 4:
                
            #     for x in range(4):
            #         cv2.circle(self.grayscale_image,(self.point_matrix[x][0],self.point_matrix[x][1]),3,(0,255,0),cv2.FILLED)
                
            #     # Showing original image
            #     cv2.imshow("Original Image ",self.grayscale_image)
            #     # Mouse click event on original image
            #     cv2.setMouseCallback("Original Image ", self.mouse_coords)
            #     # Printing updated point matrix
            #     print(self.point_matrix)
            #     # Refreshing window all time
            #     cv2.waitKey(1)               

            self.find_bottle_location()
            
            self.pancake_flag = rospy.get_param("/pancaked")
            if self.pancake_flag:
                self.find_pancake_location()

            self.flip_flag = rospy.get_param("/flipped")
            if self.flip_flag:
                self.find_lift_location()
                rospy.set_param("/flipped", False)

            self.fliptime = rospy.get_param("/flip_time")
            if self.fliptime:
                self.rgb_image = cv2.circle(self.rgb_image, (self.cx_flip,self.cy_flip), 3, (255,255,0), 3)

            self.show_video("test",self.rgb_image)

        except CvBridgeError:
            print(CvBridgeError())
            rospy.logerr("bad")
        
        return

    # def mouse_coords(self,event,x,y,flags,params):
    #     # Left button mouse click event opencv
    #     if event == cv2.EVENT_LBUTTONDOWN:
    #         self.point_matrix[counter] = x,y
            # self.point_counter += 1

    def get_intrinsics(self, camera_info):
        """ TODO
        TODO

        Args:
            camera_info (TODO) : TODO
        Returns:
            None
        """
        self.intr = rs.intrinsics()
        self.intr.width = camera_info.width
        self.intr.height = camera_info.height
        self.intr.ppx = camera_info.K[2]
        self.intr.ppy = camera_info.K[5]
        self.intr.fx = camera_info.K[0]
        self.intr.fy = camera_info.K[4]
        self.intr.model = rs.distortion.none
        self.intr.coeffs = [0.0, 0.0, 0.0, 0.0, 0.0]

        return

    def find_bottle_location(self):  
        """ Finds the location of the bottle

        TODO

        Args:
            None
        Returns:
            None
        """          

        red_low = np.array([80,10,10])
        red_up = np.array([255,255,255])

        self.redmask = cv2.inRange(self.hsv_image,red_low,red_up)

        self.masked_image = cv2.bitwise_and(self.hsv_image,self.hsv_image,mask=self.redmask)

        self.masked_image_gray = cv2.cvtColor(self.masked_image, cv2.COLOR_RGB2GRAY)
        
        ret, thresh = cv2.threshold(self.masked_image_gray, 130,255, cv2.THRESH_BINARY)

        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)

        areas = [cv2.contourArea(c) for c in contours]
        max_index = np.argmax(areas)
        cnt=contours[max_index]

        x,y,w,h = cv2.boundingRect(cnt)
        cv2.rectangle(self.rgb_image,(x,y),(x+w,y+h),(0,255,0),2)

        M = cv2.moments(cnt)
        self.cx = int(M['m10']/M['m00'])
        self.cy = int(M['m01']/M['m00'])

        cv2.circle(self.rgb_image, (self.cx,self.cy), 4, (255,0,0), 3)

        result = self.get_xyz_from_image(self.depth_image, self.cx, self.cy)

        return

    def find_pancake_location(self):
        """ Finds the location of the pancake

        TODO

        Args:
            None
        Returns:
            None
        """

        print("finding pancake?")
        self.pancake_pos = rospy.get_param("/saved_pancake_pose")
        # self.pancake_pos = self.get_xyz_from_image(self.depth_image, self.cx, self.cy)

        ###############
        # # Set up a tf broadcaster to find the pancake position in the camera frame
        # static_broadcaster = tf2_ros.StaticTransformBroadcaster()
        # pancake_world_tf = TransformStamped()
        # pancake_world_tf.header.stamp = rospy.Time.now()
        # pancake_world_tf.header.frame_id = "world" 
        # pancake_world_tf.child_frame_id = "pancake_position"
        # pancake_world_tf.transform.translation.x = self.pancake_pos[0]
        # pancake_world_tf.transform.translation.y = self.pancake_pos[1]
        # pancake_world_tf.transform.translation.z = 0.05
        # #link0_atag_tf.transform.rotation = self.robot_atag_q
        # #q1 = transformations.quaternion_about_axis(0, [0, 0, 1])
        # q2 = transformations.quaternion_from_euler(0, 0, 0)
        # rospy.logdebug_once("pancake in world frame")
        # # rospy.logerr(self.pancake_pos[0])
        # pancake_world_tf.transform.rotation.w = 1
        # static_broadcaster.sendTransform(pancake_world_tf)

        ###############


        ###########
        # Listen and find the coordinates of the pancake

        # try:
        #     listen = TransformListener()
        #     listen.waitForTransform('/pancake_position','/world',rospy.Time(), rospy.Duration(4.0))
        #     (trans, rot) = listen.lookupTransform('/pancake_position', '/world', rospy.Time(0))

        #     self.pancake_pos_cam_x = trans[0]
        #     self.pancake_pos_cam_y = trans[1]
        #     self.pancake_pos_cam_z = trans[2]
        #     rospy.logdebug_once("pancake to camera transformed successfully?")
        #     rospy.logerr_once([self.pancake_pos_cam_x, self.pancake_pos_cam_y, self.pancake_pos_cam_z])


        #     # [0.0322859394923905, -0.1464460560533358, -0.32270352659259516]

            
        # except:
        #     rospy.logerr("it's doomed")

        # rospy.sleep(0.2)

        ############
        # Find the pixel of the pancake using RS2

        # self.pancake_pos_pixel = rs.rs2_project_point_to_pixel(self.intr, [self.pancake_pos_cam_x - 0.0322859394923905, self.pancake_pos_cam_y - -0.1464460560533358, self.pancake_pos_cam_z - -0.32270352659259516])
        
        # self.pancake_pos_pixel = rs.rs2_project_point_to_pixel(self.intr, [self.pancake_pos_cam_x - 0, self.pancake_pos_cam_y - 0, self.pancake_pos_cam_z - -0.32270352659259516])
        
        # rospy.logdebug_once(self.pancake_pos_pixel)
        # self.pancake_pos_pixel[0] = -1*self.pancake_pos_pixel[0]
        # self.pancake_pos_pixel[1] = -1*self.pancake_pos_pixel[1]
        # rospy.logdebug_once("made pixel correctly")
        
        # Make a black mask
        black_mask = np.zeros((720, 1280), np.uint8)

        # rospy.logdebug(self.pancake_pos_pixel)

        # Draw a circle in the mask and RGB image
        cv2.circle(black_mask, (445,471), 110 ,255, -1)
        self.rgb_image = cv2.circle(self.rgb_image, (445,471), 110, (255,0,0), 3)

        # cv2.circle(black_mask, (int(self.pancake_pos_pixel[1]), int(self.pancake_pos_pixel[0])), 80,255, -1)
        # self.rgb_image = cv2.circle(self.rgb_image, (int(self.pancake_pos_pixel[1]), int(self.pancake_pos_pixel[0])), 80, (255,0,0), 3)

        rospy.logdebug_once("drew both circles")

        # Mask the images
        masked_img = cv2.bitwise_and(black_mask, self.grayscale_image)
        self.show_video("pancake?",masked_img)
        
        canny_pancake = cv2.Canny(masked_img,50,150, 5, L2gradient = True)

        contours, heir = cv2.findContours(canny_pancake, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        num_contours = len(contours)
        rospy.logdebug(num_contours)

        self.show_video("canny?", canny_pancake)

        self.now = rospy.Time.now()
        if self.first_frame_after_pour == False:
            if rospy.Time.now() > self.starttime + self.cooktime:
                rospy.logdebug("TIME TO FLIP, TIMED OUT")

        if self.first_frame_after_pour:
            rospy.logdebug("the first frame after pouring")
            self.starttime = rospy.Time.now()
            self.cooktime = rospy.Duration(60)
            self.orig_contour_count = num_contours
            self.first_frame_after_pour = False

        if num_contours > self.orig_contour_count * 1.2:
            self.flag2 = True
            
            rospy.logdebug("TIME TO FLIP?")

        if self.flag2 and num_contours < 70:
            rospy.logdebug("really oughta flip now")

            hull_list = []

            for i in range(len(contours)):
                hull = cv2.convexHull(contours[i])
                hull_list.append(hull)

            self.contours_by_area_flip = sorted(contours, key=cv2.contourArea, reverse=True)
            self.hulls_by_area_flip = sorted(hull_list, key=cv2.contourArea, reverse=True)

            M = cv2.moments(self.hulls_by_area_flip[1])
            self.cx_flip = int(M['m10']/M['m00'])
            self.cy_flip = int(M['m01']/M['m00'])

            self.rgb_image = cv2.circle(self.rgb_image, (self.cx_flip,self.cy_flip), 3, (255,255,0), 3)

            self.flip_coords = self.get_xyz_from_image(self.depth_image, self.cx_flip, self.cy_flip)

            rospy.set_param("/flip_location", self.flip_coords)
            rospy.logerr(self.flip_coords)
            rospy.set_param("/flip_time", True)
            rospy.set_param("/pancaked", False)

        

    def find_lift_location(self):
        
        black_mask = np.zeros((720, 1280), np.uint8)

        # Perform the same masking as before
        cv2.circle(black_mask, (445,471), 110, 255, -1)
        self.rgb_image = cv2.circle(self.rgb_image, (445,471), 110, (255,0,0), 3)

        masked_img_lift = cv2.bitwise_and(black_mask, self.grayscale_image)

        rospy.logdebug("drew a circle where we last saw the pancake, lifting this time")
        
        canny_pancake_lift = cv2.Canny(masked_img_lift,50,150, 5, L2gradient = True)

        self.show_video("canny?", canny_pancake_lift)


        contours, heir = cv2.findContours(canny_pancake_lift, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        hull_list = []

        for i in range(len(contours)):
            hull = cv2.convexHull(contours[i])
            hull_list.append(hull)

        self.contours_by_area_lift = sorted(contours, key=cv2.contourArea, reverse=True)
        self.hulls_by_area_lift = sorted(hull_list, key=cv2.contourArea, reverse=True)

        M = cv2.moments(self.hulls_by_area_lift[1])
        cx = int(M['m10']/M['m00'])
        cy = int(M['m01']/M['m00'])

        self.rgb_image = cv2.circle(self.rgb_image, (cx,cy), 3, (255,0,0), 3)

        self.lift_coords = self.get_xyz_from_image(self.depth_image, cx, cy)

        rospy.set_param("/flip_location", self.lift_coords)



    def get_xyz_from_image(self,depth_image, x,y):
        """ TODO

        TODO

        Args:
            depth_image (float) : TODO
            x (float) : TODO
            y (float) : TODO
        Returns:
            TODO
        """
        
        result = rs.rs2_deproject_pixel_to_point(self.intr, [x,y], depth_image[y,x])
        return result 

if __name__ == '__main__':
    ImageProcessing()
    rospy.spin()