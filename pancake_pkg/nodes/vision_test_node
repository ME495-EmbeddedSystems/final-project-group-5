#!/usr/bin/env python

from numpy.core.defchararray import lower
import rospy
from cv_bridge import CvBridge, CvBridgeError
from sensor_msgs.msg import Image, CompressedImage, CameraInfo
import numpy as np
import cv2
import pyrealsense2 as rs
import tf2_ros
import tf2_geometry_msgs



class ImageProcessing:

    def __init__(self):
        rospy.init_node('vision_test_node',anonymous=True, log_level=rospy.DEBUG)
        rospy.logerr("started the node")

        rospy.Subscriber("/camera/aligned_depth_to_color/image_raw", Image, callback=self.convert_depth_image, queue_size=1)
        rospy.Subscriber("/camera/color/image_raw", Image, callback=self.convert_color_image, queue_size=1)
        rospy.Subscriber("/camera/aligned_depth_to_color/camera_info", CameraInfo, callback=self.get_intrinsics, queue_size=1)
        # rospy.set_param("/pancaked", True)
        # rospy.set_param("/saved_pancake_pose", True)

        self.point_counter = 0
        self.point_matrix = np.zeros((4,2),np.int)
        self.first_frame_after_pour = True

        rospy.logerr('subscribed')

    def show_video(self, name, ros_image):
        """ TODO

        TODO

        Args:
            name (TODO) : TODO
            ros_image (TODO) : TODO
        Returns:
            None
        """
        cv2.imshow(name,ros_image)
        cv2.waitKey(3)

        return

    def convert_depth_image(self,ros_image):
        """ TODO
        
        TODO

        Args:
            ros_image (TODO) : TODO
        Returns:
            None
        """
        bridge = CvBridge()
        # Use cv_bridge() to convert the ROS image to OpenCV format
        try:
            self.depth_image = bridge.imgmsg_to_cv2(ros_image)
            depth_array = np.array(self.depth_image, dtype=np.float32)
            #self.show_video(depth_image)

        except CvBridgeError:
            print(CvBridgeError())
            rospy.logerr("bad")
        
        return

    def convert_color_image(self,ros_image):
        """ TODO

        TODO

        Args:
            ros_image (TODO) : TODO
        Returns:
            None
        """

        bridge = CvBridge()
        try:
            self.bgr_image = bridge.imgmsg_to_cv2(ros_image)
            self.hsv_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2HSV)
            self.rgb_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2RGB)
            self.grayscale_image = cv2.cvtColor(self.bgr_image, cv2.COLOR_BGR2GRAY)

            # while self.point_counter < 4:
                
            #     for x in range(4):
            #         cv2.circle(self.grayscale_image,(self.point_matrix[x][0],self.point_matrix[x][1]),3,(0,255,0),cv2.FILLED)
                
            #     # Showing original image
            #     cv2.imshow("Original Image ",self.grayscale_image)
            #     # Mouse click event on original image
            #     cv2.setMouseCallback("Original Image ", self.mouse_coords)
            #     # Printing updated point matrix
            #     print(self.point_matrix)
            #     # Refreshing window all time
            #     cv2.waitKey(1)               

            self.find_bottle_location()
            
            self.pancake_flag = rospy.get_param("/pancaked")
            if self.pancake_flag:
                self.find_pancake_location()

            self.flip_flag = rospy.get_param("/flipped")
            if self.flip_flag:
                self.find_lift_location()
                rospy.set_param("/flipped", False)

            self.show_video("test",self.rgb_image)

        except CvBridgeError:
            print(CvBridgeError())
            rospy.logerr("bad")
        
        return

    # def mouse_coords(self,event,x,y,flags,params):
    #     # Left button mouse click event opencv
    #     if event == cv2.EVENT_LBUTTONDOWN:
    #         self.point_matrix[counter] = x,y
            # self.point_counter += 1

    def get_intrinsics(self, camera_info):
        """ TODO
        TODO

        Args:
            camera_info (TODO) : TODO
        Returns:
            None
        """
        self.intr = rs.intrinsics()
        self.intr.width = camera_info.width
        self.intr.height = camera_info.height
        self.intr.ppx = camera_info.K[2]
        self.intr.ppy = camera_info.K[5]
        self.intr.fx = camera_info.K[0]
        self.intr.fy = camera_info.K[4]
        self.intr.model = rs.distortion.none
        self.intr.coeffs = [0.0, 0.0, 0.0, 0.0, 0.0]

        return

    def find_bottle_location(self):  
        """ Finds the location of the bottle

        TODO

        Args:
            None
        Returns:
            None
        """          

        red_low = np.array([80,10,10])
        red_up = np.array([255,255,255])

        self.redmask = cv2.inRange(self.hsv_image,red_low,red_up)

        self.masked_image = cv2.bitwise_and(self.hsv_image,self.hsv_image,mask=self.redmask)

        self.masked_image_gray = cv2.cvtColor(self.masked_image, cv2.COLOR_RGB2GRAY)
        
        ret, thresh = cv2.threshold(self.masked_image_gray, 130,255, cv2.THRESH_BINARY)

        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        areas = [cv2.contourArea(c) for c in contours]
        max_index = np.argmax(areas)
        cnt=contours[max_index]

        x,y,w,h = cv2.boundingRect(cnt)
        cv2.rectangle(self.rgb_image,(x,y),(x+w,y+h),(0,255,0),2)

        M = cv2.moments(cnt)
        self.cx = int(M['m10']/M['m00'])
        self.cy = int(M['m01']/M['m00'])

        cv2.circle(self.rgb_image, (self.cx,self.cy), 4, (255,0,0), 3)

        result = self.get_xyz_from_image(self.depth_image, self.cx, self.cy)

        return

    def find_pancake_location(self):
        """ Finds the location of the pancake

        TODO

        Args:
            None
        Returns:
            None
        """

        print("finding pancake?")
        self.pancake_pos = rospy.get_param("/saved_pancake_pose")
        # self.pancake_pos = self.get_xyz_from_image(self.depth_image, self.cx, self.cy)

        ###############
        # Set up a tf broadcaster to find the pancake position in the camera frame
        static_broadcaster = tf2_ros.StaticTransformBroadcaster()
        pancake_world_tf = TransformStamped()
        pancake_world_tf.header.stamp = rospy.Time.now()
        pancake_world_tf.header.frame_id = "world" 
        pancake_world_tf.child_frame_id = "pancake_position"
        pancake_world_tf.transform.translation.x = self.pancake_pos[0]
        pancake_world_tf.transform.translation.y = self.pancake_pos[1]
        pancake_world_tf.transform.translation.z = self.pancake_pos[2]
        #link0_atag_tf.transform.rotation = self.robot_atag_q
        #q1 = transformations.quaternion_about_axis(0, [0, 0, 1])
        q2 = transformations.quaternion_from_euler(0, 0, 0)
        logdebug(q2)
        link0_atag_tf.transform.rotation.w = 1
        static_broadcaster.sendTransform(pancake_world_tf)

        ###############


        ###########
        # Listen and find the coordinates of the pancake

        try:
            listen = TransformListener()
            listen.waitForTransform('/world','/pancake_position',rospy.Time(), rospy.Duration(4.0))
            (trans, rot) = listen.lookupTransform('/world', '/pancake_position', rospy.Time(0))

            self.pancake_pos_cam_x = trans[0]
            self.pancake_pos_cam_y = trans[1]
            self.pancake_pos_cam_z = 0.05
            rospy.logdebug("pancake to camera transformed successfully?")
            rospy.logerr()
            
        except:
            rospy.logerr("it's doomed")

        rospy.sleep(0.2)

        ############
        # Find the pixel of the pancake using RS2

        self.pancake_pos_pixel = rs.rs2_project_point_to_pixel(self.intr, [self.pancake_pos_cam_x, self.pancake_pos_cam_y, self.pancake_pos_cam_z])
        rospy.logdebug("made pixel correctly")
        
        # Make a black mask
        black_mask = np.zeros((720, 1280), np.uint8)

        # Draw a circle in the mask and RGB image
        cv2.circle(black_mask, (int(self.pancake_pos_pixel[0]), int(self.pancake_pos_pixel[1])), 80,255, -1)

        self.rgb_image = cv2.circle(self.rgb_image, (int(self.pancake_pos_pixel[0]), int(self.pancake_pos_pixel[1])), 80, (255,0,0), 3)
        rospy.logdebug("drew both circles")

        # Mask the images
        masked_img = cv2.bitwise_and(black_mask, self.grayscale_image)
        self.show_video("pancake?",masked_img)
        
        canny_pancake = cv2.Canny(masked_img,50,150, 5, L2gradient = True)

        contours, heir = cv2.findContours(canny_pancake, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        num_contours = len(contours)
        print(num_contours)

        if self.first_frame_after_pour:
            rospy.logdebug("the first frame after pouring")
            self.orig_contour_count = num_contours
            self.first_frame_after_pour = False

        if num_contours > self.orig_contour_count * 1.5:
            rospy.set_param("/flip_time", True)
            rospy.set_param("/pancaked", False)

    def find_lift_location(self):
        
        black_mask = np.zeros((720, 1280), np.uint8)

        # Perform the same masking as before
        cv2.circle(black_mask, (int(self.pancake_pos_pixel[0]), int(self.pancake_pos_pixel[1])), 80,255, -1)
        self.rgb_image = cv2.circle(self.rgb_image, (int(self.pancake_pos_pixel[0]), int(self.pancake_pos_pixel[1])), 150, (255,0,0), 3)

        masked_img_lift = cv2.bitwise_and(black_mask, self.grayscale_image)

        rospy.logdebug("drew a circle where we last saw the pancake, lifting this time")
        
        canny_pancake_lift = cv2.Canny(masked_img_lift,50,150, 5, L2gradient = True)

        contours, heir = cv2.findContours(canny_pancake_lift, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        hull_list = []

        for i in range(len(contours)):
            hull = cv2.convexHull(contours[i])
            hull_list.append(hull)

        self.contours_by_area = sorted(contours, key=cv2.contourArea, reverse=True)
        self.hulls_by_area = sorted(hull_list, key=cv2.contourArea, reverse=True)

        M = cv2.moments(self.hulls_by_area[0])
        cx = int(M['m10']/M['m00'])
        cy = int(M['m01']/M['m00'])

        self.rgb_image = cv2.circle(self.rgb_image, (cx,cy), 3, (255,0,0), 3)

        self.lift_coords = self.get_xyz_from_image(self.depth_image, cx, cy)

        rospy.set_param("/lift_location", self.lift_coords)



    def get_xyz_from_image(self,depth_image, x,y):
        """ TODO

        TODO

        Args:
            depth_image (float) : TODO
            x (float) : TODO
            y (float) : TODO
        Returns:
            TODO
        """
        
        result = rs.rs2_deproject_pixel_to_point(self.intr, [x,y], depth_image[y,x])
        return result 

if __name__ == '__main__':
    ImageProcessing()
    rospy.spin()